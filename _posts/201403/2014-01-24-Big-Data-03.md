---
layout: post
title: Big Data In Action 03  Hadoop配置
description: 大数据实战系列03 Hadoop配置
categories:
- Hadoop 
tags:
- Hadoop 
---

#虚拟环境单机Hadoop配置

##JDK配置

1. 下载JDK,根据自己的操作系统选择，我的是linux 64位 [地址][1]

2. 解压JDK
	
		tar -xzvf jdk-7u25-linux-x64.tar.gz

3. 配置JDK

		vim .bashrc
		输入：
		export JAVA_HOME=/home/vagrant/soft/jdk1.7.0_25
		export PATH=$PATH:$JAVA_HOME/bin
		source .bashrc
	验证是否配成功:

		java -version
	成功:
		
		vagrant@precise64:~$ java -version
		java version "1.7.0_25"
		Java(TM) SE Runtime Environment (build 1.7.0_25-b15)
		Java HotSpot(TM) 64-Bit Server VM (build 23.25-b01, mixed mode)


##Hadoop配置

1. 下载Hadoop [地址][2]


2.  解压Hadoop

		tar -xzvf hadoop-2.2.0.tar.gz 

3.  修改.bashrc
	
		vim .bashrc
		export JAVA_HOME=/home/vagrant/soft/jdk1.7.0_25
		export HADOOP_HOME=/home/vagrant/soft/hadoop-2.2.0
		export HADOOP_MAPRED_HOME=/home/vagrant/soft/hadoop-2.2.0
		export HADOOP_COMMON_HOME=/home/vagrant/soft/hadoop-2.2.0
		export HADOOP_HDFS_HOME=/home/vagrant/soft/hadoop-2.2.0
		export YARN_HOME=/home/vagrant/soft/hadoop-2.2.0
		export HADOOP_CONF_DIR=/home/vagrant/soft/hadoop-2.2.0/etc/hadoop
		export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
		source .bashrc

4. 创建Hadoop数据文件夹

		cd ~
		mkdir hadoop/data/hdfs
		mkdir hadoop/data/tmp
		mkdir hadoop/data/hdfs/datanode
		mkdir hadoop/data/hdfs/namenode

5. 修改${HADOOP_HOME}/etc/hadoop/hadoop-env.sh
		
		vim ${HADOOP_HOME}/etc/hadoop/hadoop-env.sh
		export JAVA_HOME=/home/vagrant/soft/jdk1.7.0_25

6. 修改${HADOOP_HOME}/etc/hadoop/mapred-site.xml,增加：
	
        <property>
                <name>mapreduce.framework.name</name>
                <value>yarn</value>
        </property>

7.	修改${HADOOP_HOME}/etc/hadoop/core-site.xml,增加:

		<property>
                <name>fs.default.name</name>
                <value>hdfs://precise64:8020</value>
        </property>
        <property>
                <name>hadoop.tmp.dir</name>
                <value>/home/vagrant/hadoop/data/tmp</value>
        </property>
        <property>
                <name>fs.checkpoint.period</name>
                <value>300</value>
        </property>
        <property>
                 <name>fs.checkpoint.dir</name>
                <value>${hadoop.tmp.dir}/dfs/namesecondary</value>
        </property>


8. 修改${HADOOP_HOME}/etc/hadoop/yarn-site.xml,增加：

	    <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>


9. 修改{HADOOP_HOME}/etc/hadoop/hdfs-site.xml,增加:

		<property>
                <name>dfs.replication</name>
                <value>1</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/home/vagrant/hadoop/data/hdfs/namenode</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/home/vagrant/hadoop/data/hdfs/datanode</value>
        </property>
        <property>
                <name>dfs.http.address</name>
                <value>0.0.0.0:50070</value>
        </property>
        <property>
                <name>dfs.datanode.http.address</name>
                <value>0.0.0.0:50075</value>
        </property>
		 <property>
     		 <name>dfs.permissions</name>
      		<value>false</value>
  		</property>

10. 设置免密码登录：
		
		ssh-keygen -t rsa
		cd ~/.ssh/
		cat id_rsa.pub >> authorized_keys

11. 启动Hadoop

	>第一次启动Hadoop,格式化HDFS执行

		bin/hadoop namenode -format
	
	启动HDFS:
		
		sbin/start-dfs.sh

	启动YARN:
		
		sbin/start-yarn.sh

	检查是否启动成功，执行

		vagrant@precise64:hadoop-2.2.0$ jps
		22330 Jps
		22297 NodeManager
		21890 DataNode
		22045 SecondaryNameNode
		21767 NameNode
		22191 ResourceManager
		vagrant@precise64:hadoop-2.2.0$ 
	
12. 浏览器查看
		
查看yarn, 输入 http://192.168.33.10:8088/ , 界面如下:

![显示][3]

查看HDFS, 输入 http://192.168.33.10:50070 , 界面如下:
![显示][4]


检查datanode ,namenode ,secondenamenode 日志是否正常

##问题汇总
1. 反复 `hdfs namenode -format` 多次引起hdfs中的name节点和node节点辨认ID不一致导致的问题，问题就是localhost:50070之后无法browser file system，当时配置hdfs-site.xml时dfs.namenode.name.dir 和 dfs.datanode.data.dir  所在的文件夹中current/VERSION 文件中的ID标示被改变了，解决方案是先 `stop-all.sh`   然后删除掉刚才的hdfs的目录，然后重新对hdfs `namenode -format`  然后`start-all.sh` 执行以下就可以了.

2. 虚拟机环境下，经常关闭或者重启，为了避免重新启动虚拟机，启动Hadoop出现各种问题，需要在core-site.xml 中将hadoop.tmp.dir属性设置为一个非 /tmp 目录,比如`/home/vagrant/hadoop/data/tmp`

3. 控制输出：
	
		Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
怀疑是64位系统使用了32位库，执行：

		vagrant@precise64:native$ file libhadoop.so.1.0.0

		libhadoop.so.1.0.0: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, BuildID[sha1]=0x9eb1d49b05f67d38454e42b216e053a27ae8bac9, not stripped
		vagrant@precise64:native$ 
		
	不出所料，使用了32位库，下载源代码[地址][2]重新编译(PS:如何编译见下一章)。然后用编译的64位替换掉。

		14/01/24 17:30:12 DEBUG util.NativeCodeLoader: Trying to load the custom-built native-hadoop library...
		14/01/24 17:30:12 DEBUG util.NativeCodeLoader: Loaded the native-hadoop library
		14/01/24 17:30:12 DEBUG security.JniBasedUnixGroupsMapping: Using JniBasedUnixGroupsMapping for Group resolution
	解决掉这个问题了


4. 外网连接虚拟机的问题:
	
	core-site.xml中的fs.default.name要配置为主机名，然后要检查/etc/hosts 中主机名映射的ip是否正确。因为本质上hadoop是通过RCP来互相通信的，需要创建socket连接。

###常用链接

[![给我捐款](http://c000005.qiniudn.com/donate_me.png "给我捐款")](http://me.alipay.com/0xc000005)

[回到主页][5]

                                               


[1]: http://www.oracle.com/technetwork/java/javase/downloads/index.html
[2]: http://mirrors.hust.edu.cn/apache/hadoop/common/hadoop-2.2.0/

[3]: http://c000005.qiniudn.com/3.png

[4]: http://c000005.qiniudn.com/4.png
[5]: http://0xc000005.github.io/