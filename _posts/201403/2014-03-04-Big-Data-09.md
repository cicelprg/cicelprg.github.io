---
layout:	post
title:	Big Data In Action 09  Hadoop 大规模数据排序之SecondarySort
description: 大数据实战系列09  Hadoop 大规模数据排序之SecondarySort
categories:
- Hadoop
tags:
- SecondarySort
---

###1. Secondary Sort
	
>概念： 首先按照第一字段排序，然后再对第一字段相同的行按照第二字段排序，注意不能破坏第一次排序的结果。


###2. 实现

1. 数据准备
   
    下载: [sort.txt][1]

2. 将每行数据抽象为一个IntPair类
	
		//将输入数据抽象为IntPair自定义类
		public static class IntPair implements WritableComparable<IntPair>
		{
			private int first = 0;
			private int second =  0;
			@Override
			public void write(DataOutput out) throws IOException {
				out.writeInt(first);
				out.writeInt(second);
			}
			@Override
			public void readFields(DataInput in) throws IOException {
				first = in.readInt();
				second = in.readInt();
			}
			@Override
			public boolean equals(Object obj) {
				if(obj instanceof IntPair){
					IntPair pair = (IntPair)obj;
					return first == pair.first && second == pair.second;
				}
				return false;
			}
			@Override
			public int compareTo(IntPair o) {
				if(first != o.first){
					return first < o.first ? -1 : 0;
				}else if(second != o.second){
					return second <o.second ? -1 : 0;
				}
				return 0;
			}
			public int getFirst() {
				return first;
			}
			public void setFirst(int first) {
				this.first = first;
			}
			public int getSecond() {
				return second;
			}
			public void setSecond(int second) {
				this.second = second;
			}
		}

3. 编写Mapper

			public static class MapClass extends Mapper<Object,Text,IntPair,IntWritable>{
				InitPair key = new InitPair();
				@Override
				protected void map(Object inKey, Text inValue, Context context)
				throws IOException, InterruptedException {
					String input = inValue.toString();
					String strs[]  =input.split(" ");
					key.setFirst(Integer.parseInt(strs[0]));
					key.setSecond(Integer.parseInt(strs[1]));
					context.write(key, new IntWritable(key.getSecond()));
 				}
		
			}

4. 编写Reduce

		public static class ReduceClass extends Reducer<IntPair,IntWritable,Text,IntWritable>{

		@Override
		protected void reduce(IntPair inKey, Iterable<IntWritable> values,
				Context context)
				throws IOException, InterruptedException {
				for(IntWritable value : values){
					context.write(new Text(inKey.getFirst()+""),value);
				}
			
			}
		}
	

5. 主函数

		public static void main(String[] args) throws Exception {
	
			Configuration conf = ConfigurationFactory.createConfigure();
			Job job = Job.getInstance(conf);
			job.setJobName("Second Sort");
			job.setJarByClass(SecondarySort.class);
		
			job.setMapperClass(MapClass.class);
			job.setReducerClass(ReduceClass.class);
		
			job.setMapOutputKeyClass(IntPair.class);
			job.setMapOutputValueClass(IntWritable.class);
			

			job.setOutputKeyClass(Text.class);
			job.setOutputValueClass(IntWritable.class);
		
			FileInputFormat.addInputPath(job, new Path("/input/exam03"));  
        	FileOutputFormat.setOutputPath(job, new Path("/output/exam03"));  
        	System.exit(job.waitForCompletion(true)?0:1);  

		}

6. 运行代码：

	输出如下![代码][2]

	我们发现这段代码没有对数据进行排序，只是原样输出。接下来我们要建立比较类。

7. 首先我们建立IntPair类的比较器，并且注册

	代码如下：
			
		public static class Comparator extends WritableComparator{

			public Comparator() {
				super(IntPair.class);
			}
			@Override
			public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) {
				return compareBytes(b1, s1, l1, b2, s2, l2);
			}
		}
	
    	static {                                        
        	WritableComparator.define(IntPair.class, new Comparator());
    	}


8. 对IntPair进行分组比较, 第一次比较

	代码如下:

		public static class GroupingComparator implements RawComparator<IntPair>{

			@Override
			public int compare(IntPair o1, IntPair o2) {
				int left = o1.getFirst();
				int right  = o2.getSecond();
			
				return left == right ? 0 : ( left < right ? -1 : 1);
			}

			@Override
			public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2, int l2) {
				return WritableComparator.compareBytes(b1, s1, l1, b2, s2, l2);
			}
		
		}

	主函数中追加:
		
		job.setGroupingComparatorClass(GroupingComparator.class);


9. 分组完之后，因为Key为IntPair类，又会调用它的比较函数进行二次比较.


10. 再次运行输出
	![第二次输出][3]
	
	我们发现整个数据已经排序正确。


11. [下载代码][4]

###常用链接
**捧个钱场**

[![给我捐款](http://c000005.qiniudn.com/donate_me.png "给我捐款")](http://me.alipay.com/0xc000005)

[回到主页][5]

                                       
[1]: sort.txt
[2]: http://c000005.qiniudn.com/12.PNG
[3]: http://c000005.qiniudn.com/13.PNG
[4]: https://github.com/0xC000005/Hadoop
[5]: http://0xc000005.github.io/
