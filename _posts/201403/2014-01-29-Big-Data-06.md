---
layout: post
title: Big Data In Action 06  HDFS Java API
description: 大数据实战系列06 HDFS Java API
categories:
- Hadoop 
tags:
- HDFS
---

##Java API 操作 HDFS

1. 创建Configuration

		ConfigurationFactory.java
		import org.apache.hadoop.conf.Configuration;

		public class ConfigurationFactory {
				public static Configuration config;

				private ConfigurationFactory() {
				}

				public static Configuration getInstance() {
					if (config == null) {
						config = new Configuration();
						config.addResource("/MyHadoop/conf/core-site.xml");
					}
					return config;
				}
		}

2. 创建目录或者文件
	
		public static void createFile(String path) {
			try {
				Configuration conf = ConfigurationFactory.getInstance();
				FileSystem fs = FileSystem.get(conf);
				fs.create(new Path(path));
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

3. 删除文件或者目录

		
		public static void delteFile(String path){
			try {
				Configuration conf = ConfigurationFactory.getInstance();
				FileSystem fs = FileSystem.get(conf);
				fs.delete(new Path(path),false);
			} catch (IOException e) {
				e.printStackTrace();
			}
		}

4. 遍历文件或者目录


			public static void listFile(String path) {
			try {
				Configuration conf = ConfigurationFactory.getInstance();
				FileSystem fs = FileSystem.get(conf);
				FileStatus[] status = fs.listStatus(new Path(path));
				for (FileStatus file : status) {
					System.out.println(file.getPath());
				}
			} catch (IOException e) {
				e.printStackTrace();
			}
		}	


5. 写文件

	
		import java.io.IOException;

		import org.apache.hadoop.conf.Configuration;

		import org.apache.hadoop.fs.FSDataOutputStream;

		import org.apache.hadoop.fs.FileSystem;

		import org.apache.hadoop.fs.Path;


		public class WriteFile {
	
			public static void main(String[] args) throws IOException {
		
			Configuration conf = new Configuration();
			FileSystem fs = FileSystem.get(conf);
			Path path = new Path("/user/hadoop/data/write.txt");
			FSDataOutputStream out = fs.create(path);
			out.writeUTF("da jia hao,cai shi zhen de hao!");
			fs.close();
	
			}
	
		}

6.	上传本地文件到HDFS

		import java.io.IOException;


		import org.apache.hadoop.conf.Configuration;

		import org.apache.hadoop.fs.FileSystem;
	
		import org.apache.hadoop.fs.Path;
	



		public class CopyFromLocalFile {

		public static void main(String[] args) throws IOException {
		
		Configuration conf = new Configuration();
		FileSystem fs = FileSystem.get(conf);
		Path src = new Path("/home/hadoop/word.txt");
		Path dst = new Path("/user/hadoop/data/");
		fs.copyFromLocalFile(src, dst);
		fs.close();
			}	

		}

 

7. 运行效果:
	![效果][2]

更多API参考[地址][1]


##问题
1. org.apache.hadoop.security.AccessControlException: Permission denied
集群之外创建文件权限不够
解决办法：
	
		added this entry to conf/hdfs-site.xml

		<property>
			<name>dfs.permissions</name>
			<value>false</value>
		</property>

###常用链接

**捧个钱场**

[![给我捐款](https://img.alipay.com/sys/personalprod/style/mc/btn-index.png "给我捐款")](http://me.alipay.com/0xc000005)

[回到主页][5]

                                               


[1]: http://hadoop.apache.org/docs/r2.2.0/api/index.html


[2]: http://c000005.qiniudn.com/5.png

[5]: http://0xc000005.github.io/